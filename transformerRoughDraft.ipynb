{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMCsRjEc1bnIFzuRE2Fj5tv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"DtZU8eMVzIqm","executionInfo":{"status":"ok","timestamp":1693161074879,"user_tz":240,"elapsed":4284,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","# from collections import OrderedDict"]},{"cell_type":"code","source":["# import os\n","# # import pickle\n","# import requests\n","\n","# input_file_path = os.path.join(os.path.dirname(__file__), 'input.txt')\n","# if not os.path.exists(input_file_path):\n","#     data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n","#     with open(input_file_path, 'w') as f:\n","#         f.write(requests.get(data_url).text)\n","\n","# with open(input_file_path, 'r') as f:\n","#     data = f.read()\n","# print(f\"length of dataset in characters: {len(data):,}\")\n","\n","# # get all the unique characters that occur in this text\n","# chars = sorted(list(set(data)))\n","# vocab_size = len(chars)\n","# print(\"all the unique characters:\", ''.join(chars))\n","# print(f\"vocab size: {vocab_size:,}\")"],"metadata":{"id":"-ZhQ_uH7Xm5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# import pickle\n","import requests\n","\n","data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n","data = requests.get(data_url).text\n","\n","print(f\"length of dataset in characters: {len(data):,}\")\n","\n","# get all the unique characters that occur in this text\n","chars = sorted(list(set(data)))\n","vocab_size = len(chars)\n","print(\"all the unique characters:\", ''.join(chars))\n","print(f\"vocab size: {vocab_size:,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o74a5-tFYeMp","executionInfo":{"status":"ok","timestamp":1693161075314,"user_tz":240,"elapsed":440,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"4915f74c-5e3f-4b68-8993-d2d38ee0d781"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset in characters: 1,115,394\n","all the unique characters: \n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","vocab size: 65\n"]}]},{"cell_type":"code","source":["#need to work on batch size etc below==================\n","gVocabSize = vocab_size #assuming we are doing character based prediction\n","gChannelsWanted = 64 # hopefully a good enough embdding to learn required features (512 in the paper)\n","gTokens = chars\n","gD_k = gChannelsWanted\n","gDff = 128 #2048 in the paper\n","gParallelHeads = 4\n","gNLayers = 1\n","gBatchSize = 5\n","gBlockSize = 10\n","gLearningRate = 1e-3\n","gPos = torch.arange(0, gBlockSize, dtype=torch.long)\n","gEpochs = 5\n","\n","vocab = gTokens # !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","tokenMapping = {k:v for v, k in enumerate(vocab)} #make dict where value is index of token and key is token itself\n","\n","def myDataLoader(dataSet, batchSize, blockSize):\n","  batch = []\n","  toPredict = []\n","  i = 0\n","  block = 0\n","  for b in range(0, len(dataSet)//blockSize):\n","    batch.append(dataSet[block : (block + blockSize)])\n","    toPredict.append(dataSet[block + 1 : (block + 1 + blockSize)])\n","    block += blockSize\n","    if (b+1) % batchSize == 0:\n","      yield batch, toPredict\n","      batch = []\n","      toPredict = []\n","\n","#====\n","wordToTensor = lambda sInput, tokenMapping: [tokenMapping[letter] for letter in sInput] # to get numerical tensor to feed into nn.Embedding function (each letter has it's index)\n","tensorToWord = lambda sIndexes, tokenMapping: [list(tokenMapping.keys())[i.item()] for i in sIndexes]\n","\n","class LayerNorm(nn.Module):\n","    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n","\n","    def __init__(self, ndim, bias):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.ones(ndim))\n","        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n","\n","    def forward(self, input):\n","        return F.layer_norm(input,self.weight.shape, self.weight, self.bias, 1e-5)\n","\n","#trying to make it more modular so put attention as a separate class on it's own\n","class multiHeadAttn(nn.Module):\n","  def __init__(self, dFf, d_k, n_heads, vocabSize, blockSize):\n","    super().__init__()\n","    self.d_k = d_k\n","    self.n_heads = n_heads\n","    self.dModel = d_k  #512 in the paper\n","    self.dFf = dFf # 2048 in the paper\n","    self.encodeQ = nn.Linear(d_k, d_k) #to include in backpropogation graph you need to use \"self.\"\n","    self.encodeK = nn.Linear(d_k, d_k)\n","    self.encodeV = nn.Linear(d_k, d_k)\n","\n","  def forward(self, qkv):\n","    B, T, C = qkv.size()\n","\n","    Q = self.encodeQ(qkv)#same process for all 3 (see paper multi-head attn figure)\n","    K = self.encodeK(qkv)\n","    V = self.encodeV(qkv)\n","\n","    Q = Q.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","    K = K.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","    V = V.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","\n","    #see (Q*K.T)/sqrt(d^k) in paper (this is self-attention where the embeddings are self-multiplied and trained separately\n","    # for example, 3 x 32 becomes 3 x 3 self score where one element will eventually figure out it's relation to members of neighbouring timesteps\n","    # maybe we can make a heat map for this and see how it progresses over time\n","    QkDotProduct = torch.matmul(Q,K.transpose(-2,-1))/torch.sqrt(torch.Tensor([self.d_k]))# B, T, T\n","    #each row is 1 timestep more\n","    successiveTokensMask = torch.tril(torch.ones(T,T)).view(1,1,T,T)\n","    # setting everything ahead of the mask to infinity to make sure labels aren't included in training data\n","    QkDotProduct = QkDotProduct.masked_fill(successiveTokensMask[:,:,:T,:T] == 0, float('-inf'))\n","    #gives scores per query with respect to the key it matches (softmax on final dim with shape = B, T, C)\n","    dotProdAttn = torch.softmax(QkDotProduct, dim=-1)\n","    #multiply attn weights with \"V\". The softmax after the mask forces the division of attention based on how many words there are in the sample\n","    headOutput = torch.matmul(dotProdAttn, V)\n","    headOutput = headOutput.transpose(1,2).contiguous().view(B,T,C)\n","\n","    return headOutput\n","\n","class DecoderBlock(nn.Module):\n","  def __init__(self, dFf, d_k, n_heads, vocabSize, blockSize):\n","    super().__init__()\n","    self.selfAttn = multiHeadAttn(dFf, d_k, n_heads, vocabSize, blockSize)\n","\n","    self.FFN = nn.Sequential(\n","                nn.Linear(d_k, dFf),\n","                nn.ReLU(),\n","                nn.Linear(dFf, d_k)\n","        )\n","    self.ln = LayerNorm(d_k, False)\n","\n","\n","  def forward(self, qkv):\n","    x = self.selfAttn(qkv)\n","    x = x + self.ln(x)\n","    x = self.FFN(x)\n","    x = x + self.ln(x)\n","    return x\n","\n","\n","class theTransformer(nn.Module):\n","  def __init__(self, attnLayers, dFf, d_k, parallelHeads, vocabSize, blockSize):\n","    super().__init__()\n","    self.d_k = d_k\n","    self.embedTok = nn.Embedding(vocabSize, d_k) #vocabSize, channelsWanted\n","    self.embedPos = nn.Embedding(blockSize, d_k) #vocabSize, channelsWanted\n","    self.decoder = DecoderBlock(dFf, d_k, parallelHeads, vocabSize, blockSize) #instantiate decoder block\n","    self.layers = nn.ModuleList([self.decoder for decoders in range(attnLayers)])\n","    self.LinearFinal = nn.Linear(self.d_k, vocabSize)\n","\n","  def forward(self, batchData, target, pos, training = True):\n","    x = self.embedTok(batchData) + self.embedPos(pos)\n","    for l in self.layers: # running through all the decoder layers we wanted\n","      x = l(x)\n","    logits = self.LinearFinal(x) # get per token logits for later backprop\n","    B,T,C = logits.shape\n","\n","    logits = torch.softmax(logits, dim = 1) # get per token probabilities for later backprop\n","\n","    #the cross_entropy function has dimension requirement which we solve by making pred dim = (B*T, C) and target dim = (B*T) (C is classes not channels, while target has ground truth so only 1 class)\n","    # pred, target = logits.view(B*T, C), torch.LongTensor(target).view(B*T)\n","    pred, target = logits.view(B*T, C), F.one_hot(torch.LongTensor(target).view(B*T), num_classes = 65).type(torch.FloatTensor)#if we want to use softmax (need to convert one-hot encoding to float so it can actually do cross entropy operations with pred which is float)\n","\n","    if training:\n","      loss = F.cross_entropy(pred, target)\n","    else:\n","      loss = 0\n","\n","    return loss, logits\n","\n","numericRepresentation = wordToTensor(data,tokenMapping) #changing character to index-based integer\n","finalTransformer = theTransformer(gNLayers, gDff, gD_k, gParallelHeads, gVocabSize, gBlockSize)\n","finalTransformer.to(device = 'cpu')\n","optimizer = torch.optim.Adam(finalTransformer.parameters(), lr=gLearningRate) #make optimizer for the decoder block\n","\n","i = 0\n","\n","for e in range(gEpochs):\n","  for batchData, forwardPrediction in myDataLoader(numericRepresentation, gBatchSize, gBlockSize):\n","    optimizer.zero_grad()\n","    loss, outputLogits = finalTransformer(torch.IntTensor(batchData), torch.LongTensor(forwardPrediction) , gPos)\n","    loss.backward()\n","    optimizer.step()\n","\n","    i+=1\n","    # break\n","    if i % 1000 == 0:\n","      print(loss)\n","\n","    if i == 100000:\n","      break\n","\n","#====================================\n"],"metadata":{"id":"Cru_mIk-zO8H","colab":{"base_uri":"https://localhost:8080/","height":427},"executionInfo":{"status":"error","timestamp":1692490297531,"user_tz":240,"elapsed":19543,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"153e3508-51e6-47e2-9d2a-5d852b2e3f27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4.0387, grad_fn=<DivBackward1>)\n","tensor(4.0325, grad_fn=<DivBackward1>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-c6d059c18c23>\u001b[0m in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatchData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforwardPrediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericRepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgBlockSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwardPrediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgPos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-c6d059c18c23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batchData, target, pos, training)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# running through all the decoder layers we wanted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearFinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get per token logits for later backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-c6d059c18c23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qkv)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselfAttn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"GrElIAJePduz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"MOH1JGM_PdxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ymd1g1lMMyS0","executionInfo":{"status":"ok","timestamp":1692410244825,"user_tz":240,"elapsed":124,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"10a9bf95-bd83-4e01-e1f7-8bafb1dd5ee0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# tokEmbedded.shape"],"metadata":{"id":"2QLaHOEPle2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for p in finalTransformer.parameters():\n","#   print(p.shape)"],"metadata":{"id":"dCAPg4uhARiq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def outputWords(indices):\n","  s=''\n","  for els in indices:\n","    for ss in tensorToWord(els, tokenMapping):\n","      s += ss\n","    print(s)\n","    s = ''"],"metadata":{"id":"yeKqqgcQ9CA9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ii = torch.IntTensor(batchData)\n","iii = torch.max(outputLogits, dim = 2)[1]\n","outputWords(ii)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Hl1gDwwi7EW","executionInfo":{"status":"ok","timestamp":1692490322720,"user_tz":240,"elapsed":165,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"3e7ad654-31c6-497d-d0fd-24d4b4a32c42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ut to him: an eagle, madam,\n","Hath not so green, so \n","quick, so fair an eye\n","As Paris hath. Beshrew my ve\n","ry heart,\n","I think you are happy in this second mat\n","ch,\n","For it excels your first: or if it did not,\n","Yo\n","ur first is dead; or 'twere as good he were,\n","As li\n"]}]},{"cell_type":"code","source":["outputWords(iii)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OD8jbTxqH-l","executionInfo":{"status":"ok","timestamp":1692490327400,"user_tz":240,"elapsed":226,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"f2bb16a9-4c99-419a-bca0-8afdcab7fb0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hj;worii,thnbifhesg!\n","T:av meEmEvi'EcdEU.Upiuy.p-x.\n","'chuciekvi?d-,bour\n","A:E bv'ta'mUfZwnZmgss:!myl;apax\n","by;sthan..e\n","T:eEU c-vgorw-armol!xwxuwx-ld,-bk-b'ui\n","jt,bofh-\n","WEb:evg'cs:cyx--mourmyriiv''w'l.?c.?'cofl\n","gh,\n","IE saEU plcoferi-wird:i:yvd\n","BEuyrud,bkbUn.v?vu\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XIN18bEiqXUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RrJM_ExFUPhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZhtCRk27UPkQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputWords(torch.IntTensor([[47, 56, 57, 58,  1, 40, 53, 42, 46, 52]])),\n","outputWords(torch.IntTensor([[43, 52, 10,  0, 14, 53, 44, 53, 56, 57]])),\n","outputWords(torch.IntTensor([[ 1, 61, 43,  0, 54, 56, 53, 42, 46, 57]]))\n","# tensor([[42,  1, 39, 52, 63,  6, 61, 59, 56, 43]])\n","# tensor([[46, 43, 56,  6,  1, 40, 53, 39, 52, 58]])\n","# tensor([[51, 43,  1, 57, 46, 53, 39, 50, 47,  0]])\n","# tensor([[27, 13, 50, 33, 10,  0, 32, 47, 43, 56]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Un1Cm6h0wOg0","executionInfo":{"status":"ok","timestamp":1692417911552,"user_tz":240,"elapsed":121,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"b4dcd272-7dd6-4e70-e54a-75abb9412ca2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["irst bodhn\n","en:\n","Bofors\n"," we\n","prodhs\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IrnaShcdqXc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","forwardIndices = torch.LongTensor(forwardPrediction)\n","B, T = forwardIndices.shape\n","forwardIndices.view(B*T)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Ak4aFs6RUCz","executionInfo":{"status":"ok","timestamp":1692311677613,"user_tz":240,"elapsed":156,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"80f3296b-a120-4951-c3fb-eb019cbe132b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 1, 51, 39, 52, 63,  1, 57, 58, 39, 52, 42,  0, 44, 53, 56,  1, 41, 53,\n","        52, 57, 59, 50, 57, 46, 47, 54, 57, 12,  0,  0, 31, 43, 41, 53, 52, 42,\n","         1, 27, 44, 44, 47, 41, 43, 56, 10,  0, 32, 46, 56, 43])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import os\n","import requests\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from datetime import datetime\n","\n","def saveModel(model, pathReq = None, colab = True):\n","\n","  fileName = 'model_' + str(datetime.now()).replace('-','').replace(':','').replace(' ','')[:14] + '.pth'\n","\n","  if colab and pathReq is None:\n","    filePath = '/content/drive/MyDrive/myRepository/savedModels/' + fileName\n","  else:\n","    filePath = os.getcwd() + '/' + fileName\n","\n","  torch.save(model.state_dict(), filePath)\n","\n","  print('model saved in {}'.format(filePath))\n","\n","def getRawData():\n","  data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n","  data = requests.get(data_url).text\n","\n","  print(f\"length of raw dataset: {len(data):,}\")\n","\n","  # get all the unique characters that occur in this text\n","  possibleTokens = sorted(list(set(data)))\n","\n","  return data, possibleTokens, len(possibleTokens)\n","\n","\n","def myDataLoader(dataSet, batchSize, blockSize):\n","  batch = []\n","  toPredict = []\n","  i = 0\n","  block = 0\n","  toShuffle = np.arange(0,batchSize)\n","  np.random.shuffle(toShuffle)\n","\n","  for b in range(0, len(dataSet)//blockSize):\n","    batch.append(dataSet[block : (block + blockSize)])\n","    toPredict.append(dataSet[block + 1 : (block + 1 + blockSize)]) #adding next letter for the one to predict\n","    block += blockSize\n","    if (b+1) % batchSize == 0:\n","      # yield batch, toPredict\n","      yield np.array(batch)[toShuffle], np.array(toPredict)[toShuffle]\n","      batch = []\n","      toPredict = []\n","#====\n","\n","wordToTensor = lambda sInput, tokenMapping: [tokenMapping[letter] for letter in sInput] # to get numerical tensor to feed into nn.Embedding function (each letter has it's index)\n","tensorToWord = lambda sIndexes, tokenMapping: [list(tokenMapping.keys())[i.item()] for i in sIndexes]\n","\n","class LayerNorm(nn.Module):\n","    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n","\n","    def __init__(self, ndim, bias):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.ones(ndim))\n","        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n","\n","    def forward(self, input):\n","        return F.layer_norm(input,self.weight.shape, self.weight, self.bias, 1e-5)\n","\n","#trying to make it more modular so put attention as a separate class on it's own\n","class multiHeadAttn(nn.Module):\n","  def __init__(self, dFf, d_k, n_heads, vocabSize, blockSize, processor = 'cpu'):\n","    super().__init__()\n","    self.d_k = d_k\n","    self.n_heads = n_heads\n","    self.dModel = d_k  #512 in the paper\n","    self.dFf = dFf # 2048 in the paper\n","    self.processor = processor\n","    self.encodeQ = nn.Linear(d_k, d_k).to(device = processor) #to include in backpropogation graph you need to use \"self.\"\n","    self.encodeK = nn.Linear(d_k, d_k).to(device = processor)\n","    self.encodeV = nn.Linear(d_k, d_k).to(device = processor)\n","\n","  def forward(self, qkv):\n","    B, T, C = qkv.size()\n","\n","    Q = self.encodeQ(qkv).to(device = self.processor)#same process for all 3 (see paper multi-head attn figure)\n","    K = self.encodeK(qkv).to(device = self.processor)\n","    V = self.encodeV(qkv).to(device = self.processor)\n","\n","    Q = Q.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","    K = K.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","    V = V.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","\n","    #see (Q*K.T)/sqrt(d^k) in paper (this is self-attention where the embeddings are self-multiplied and trained separately\n","    # for example, 3 x 32 becomes 3 x 3 self score where one element will eventually figure out it's relation to members of neighbouring timesteps\n","    # maybe we can make a heat map for this and see how it progresses over time\n","    QkDotProduct = torch.matmul(Q,K.transpose(-2,-1))/torch.sqrt(torch.Tensor([self.d_k]).to(device = self.processor))# B, T, T\n","    #each row is 1 timestep more\n","    successiveTokensMask = torch.tril(torch.ones(T,T)).view(1,1,T,T).to(device = self.processor)\n","    # setting everything ahead of the mask to infinity to make sure labels aren't included in training data\n","    QkDotProduct = QkDotProduct.masked_fill(successiveTokensMask[:,:,:T,:T] == 0, float('-inf'))\n","    #gives scores per query with respect to the key it matches (softmax on final dim with shape = B, T, C)\n","    dotProdAttn = torch.softmax(QkDotProduct, dim=-1)\n","    #multiply attn weights with \"V\". The softmax after the mask forces the division of attention based on how many words there are in the sample\n","    headOutput = torch.matmul(dotProdAttn, V)\n","    headOutput = headOutput.transpose(1,2).contiguous().view(B,T,C)\n","\n","    return headOutput\n","\n","class DecoderBlock(nn.Module):\n","  def __init__(self, dFf, d_k, n_heads, vocabSize, blockSize, processor = 'cpu'):\n","    super().__init__()\n","    self.selfAttn = multiHeadAttn(dFf, d_k, n_heads, vocabSize, blockSize, processor)\n","\n","    self.FFN = nn.Sequential(\n","                nn.Linear(d_k, dFf).to(device = processor),\n","                nn.ReLU().to(device = processor),\n","                nn.Linear(dFf, d_k).to(device = processor)\n","        ).to(device = processor)\n","\n","    self.ln = LayerNorm(d_k, False).to(device = processor)\n","\n","\n","  def forward(self, qkv):\n","    x = self.selfAttn(qkv)\n","    x = x + self.ln(x)\n","    x = self.FFN(x)\n","    x = x + self.ln(x)\n","    return x\n","\n","class theTransformer(nn.Module):\n","  def __init__(self, attnLayers, dFf, d_k, parallelHeads, vocabSize, blockSize, processor = 'cpu'):\n","    super().__init__()\n","    self.d_k = d_k\n","    self.embedTok = nn.Embedding(vocabSize, d_k).to(device = processor) #vocabSize, channelsWanted\n","    self.embedPos = nn.Embedding(blockSize, d_k).to(device = processor) #vocabSize, channelsWanted\n","    self.decoder = DecoderBlock(dFf, d_k, parallelHeads, vocabSize, blockSize, processor) #instantiate decoder block\n","    self.layers = nn.ModuleList([self.decoder for decoders in range(attnLayers)]).to(device = processor)\n","    self.LinearFinal = nn.Linear(self.d_k, vocabSize).to(device = processor)\n","    self.processor = processor\n","\n","  def forward(self, batchData, target, pos, training = True, softmax = True):\n","    x = self.embedTok(batchData) + self.embedPos(pos)\n","    for l in self.layers: # running through all the decoder layers we wanted\n","      x = l(x)\n","    logits = self.LinearFinal(x) # get per token logits for later backprop\n","    B,T,C = logits.shape\n","\n","    if softmax:\n","      logits = torch.softmax(logits, dim = 1) # get per token probabilities for later backprop\n","\n","      #the cross_entropy function has dimension requirement which we solve by making pred dim = (B*T, C) and target dim = (B*T) (C is classes not channels, while target has ground truth so only 1 class)\n","      pred, target = logits.view(B*T, C), F.one_hot(target.long().view(B*T), num_classes = 65).type(torch.FloatTensor).to(device = self.processor)#if we want to use softmax (need to convert one-hot encoding to float so it can actually do cross entropy operations with pred which is float)\n","    else:\n","      pred, target = logits.view(B*T, C), target.long().view(B*T)\n","\n","    if training:\n","      #remember, targets are offset by one token to the future, so this loss function pushes the model towards predicting the next token using the encoded information\n","      loss = F.cross_entropy(pred, target).to(device = self.processor)\n","    else:\n","      # logits = logits.view(B*T, C) #\n","      logits = logits[:, [-1],:]\n","      loss = None\n","\n","    return loss, logits\n","\n","\n","def train(data, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, lEpochs, softmax, lLearningRate, processor = 'cpu'):\n","\n","  split = int(0.9*len(data)) #decided that we can se 90% on the dataset\n","  valData = data[split:]\n","  data = data[:split]\n","\n","  numericRepresentation = wordToTensor(data,tokenMapping) #changing character to index-based integer\n","\n","  finalTransformer = theTransformer(lNLayers, lDff, lD_k, lParallelHeads, lVocabSize, lBlockSize, processor)\n","\n","  finalTransformer.to(device = processor)\n","\n","  optimizer = torch.optim.Adam(finalTransformer.parameters(), lr=lLearningRate) #make optimizer for the decoder block\n","\n","  i = 0\n","  measurementsPerEpoch = 10\n","  # resolutionFactor = (1/(measurementsPerEpoch))\n","  dataLength = len(data)\n","\n","  for e in range(lEpochs):\n","    for batchData, forwardPrediction in myDataLoader(numericRepresentation, lBatchSize, lBlockSize):\n","      optimizer.zero_grad()\n","      loss, outputLogits = finalTransformer(torch.IntTensor(batchData).to(device = processor), torch.LongTensor(forwardPrediction).to(device = processor) , lPos.to(device = processor), softmax=softmax)\n","      loss.backward()\n","      optimizer.step()\n","\n","      i += 1\n","      # print(int((len(data)/len(batchData)) / measurementsPerEpoch))\n","      if  i % int((dataLength/(lBatchSize*lBlockSize)) / measurementsPerEpoch) == 0:\n","        print(e, loss)\n","\n","      if i  % int((dataLength/(lBatchSize*lBlockSize)) / (measurementsPerEpoch / 5)) == 0 :\n","        saveModel(finalTransformer)\n","        val(finalTransformer, valData, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, softmax, lLearningRate, measurementsPerEpoch, processor)\n","        i = 0\n","        finalTransformer.train()\n","\n","def val(transformerEvalModel, dataVal, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, softmax, lLearningRate, measurementsPerEpoch, processor = 'cpu'):\n","\n","  numericRepresentationEval = wordToTensor(dataVal,tokenMapping) #changing character to index-based integer\n","\n","  transformerEvalModel.to(device = processor)\n","\n","  ii = 0\n","\n","  transformerEvalModel.eval()\n","\n","  print('validation set:')\n","\n","  dataLength = len(dataVal)\n","  with torch.no_grad():\n","    for  batchData, forwardPrediction in myDataLoader(numericRepresentationEval, lBatchSize, lBlockSize):\n","      loss, outputLogits = transformerEvalModel(torch.IntTensor(batchData).to(device = processor), torch.LongTensor(forwardPrediction).to(device = processor) , lPos.to(device = processor), softmax=softmax)\n","\n","      ii += 1\n","      # print(int((dataLength/(lBatchSize*lBlockSize)) / (measurementsPerEpoch / 5)))\n","      if ii  % int((dataLength/(lBatchSize*lBlockSize)) / (measurementsPerEpoch / 5)) == 0:\n","        print('validation loss: ', loss)\n","        ii = 0\n","\n","#====================================\n"],"metadata":{"id":"EQPlbN2T0cNk","executionInfo":{"status":"ok","timestamp":1693155383007,"user_tz":240,"elapsed":2917,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a78dc97-e0fe-462d-f246-d29970e84da7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import requests\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from datetime import datetime\n","\n","def saveModel(model, pathReq = None, colab = True):\n","\n","  fileName = 'model_' + str(datetime.now()).replace('-','').replace(':','').replace(' ','')[:14] + '.pth'\n","\n","  if colab and pathReq is None:\n","    filePath = '/content/drive/MyDrive/myRepository/savedModels/' + fileName\n","  else:\n","    filePath = os.getcwd() + '/' + fileName\n","\n","  torch.save(model, filePath)\n","\n","  print('model saved in {}'.format(filePath))\n","\n","def getRawData():\n","  data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n","  data = requests.get(data_url).text\n","\n","  print(f\"length of raw dataset: {len(data):,}\")\n","\n","  # get all the unique characters that occur in this text\n","  possibleTokens = sorted(list(set(data)))\n","\n","  return data, possibleTokens, len(possibleTokens)\n","\n","\n","def myDataLoader(dataSet, batchSize, blockSize):\n","  batch = []\n","  toPredict = []\n","  i = 0\n","  block = 0\n","  toShuffle = np.arange(0,batchSize)\n","  np.random.shuffle(toShuffle)\n","\n","  for b in range(0, len(dataSet)//blockSize):\n","    batch.append(dataSet[block : (block + blockSize)])\n","    toPredict.append(dataSet[block + 1 : (block + 1 + blockSize)]) #adding next letter for the one to predict\n","    block += blockSize\n","    if (b+1) % batchSize == 0:\n","      # yield batch, toPredict\n","      yield np.array(batch)[toShuffle], np.array(toPredict)[toShuffle]\n","      batch = []\n","      toPredict = []\n","#====\n","\n","wordToTensor = lambda sInput, tokenMapping: [tokenMapping[letter] for letter in sInput] # to get numerical tensor to feed into nn.Embedding function (each letter has it's index)\n","tensorToWord = lambda sIndexes, tokenMapping: [list(tokenMapping.keys())[i.item()] for i in sIndexes]\n","\n","class LayerNorm(nn.Module):\n","    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n","\n","    def __init__(self, ndim, bias):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.ones(ndim))\n","        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n","\n","    def forward(self, input):\n","        return F.layer_norm(input,self.weight.shape, self.weight, self.bias, 1e-5)\n","\n","#trying to make it more modular so put attention as a separate class on it's own\n","class multiHeadAttn(nn.Module):\n","  def __init__(self, dFf, d_k, n_heads, vocabSize, blockSize, processor = 'cpu'):\n","    super().__init__()\n","    self.d_k = d_k\n","    self.n_heads = n_heads\n","    self.dModel = d_k  #512 in the paper\n","    self.dFf = dFf # 2048 in the paper\n","    self.processor = processor\n","    self.encodeQ = nn.Linear(d_k, d_k)#.to(device = processor) #to include in backpropogation graph you need to use \"self.\"\n","    self.encodeK = nn.Linear(d_k, d_k)#.to(device = processor)\n","    self.encodeV = nn.Linear(d_k, d_k)#.to(device = processor)\n","\n","  def forward(self, qkv):\n","    B, T, C = qkv.size()\n","\n","    Q = self.encodeQ(qkv)#.to(device = self.processor)#same process for all 3 (see paper multi-head attn figure)\n","    K = self.encodeK(qkv)#.to(device = self.processor)\n","    V = self.encodeV(qkv)#.to(device = self.processor)\n","\n","    Q = Q.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","    K = K.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","    V = V.view(B, T, self.n_heads, C // self.n_heads).transpose(1,2) #B, heads, T, C\n","\n","    #see (Q*K.T)/sqrt(d^k) in paper (this is self-attention where the embeddings are self-multiplied and trained separately\n","    # for example, 3 x 32 becomes 3 x 3 self score where one element will eventually figure out it's relation to members of neighbouring timesteps\n","    # maybe we can make a heat map for this and see how it progresses over time\n","    QkDotProduct = torch.matmul(Q,K.transpose(-2,-1))/torch.sqrt(torch.Tensor([self.d_k]).to(device = self.processor))# B, T, T\n","    #each row is 1 timestep more\n","    successiveTokensMask = torch.tril(torch.ones(T,T)).view(1,1,T,T).to(device = self.processor)\n","    # setting everything ahead of the mask to infinity to make sure labels aren't included in training data\n","    QkDotProduct = QkDotProduct.masked_fill(successiveTokensMask[:,:,:T,:T] == 0, float('-inf'))\n","    #gives scores per query with respect to the key it matches (softmax on final dim with shape = B, T, C)\n","    dotProdAttn = torch.softmax(QkDotProduct, dim=-1)\n","    #multiply attn weights with \"V\". The softmax after the mask forces the division of attention based on how many words there are in the sample\n","    headOutput = torch.matmul(dotProdAttn, V)\n","    headOutput = headOutput.transpose(1,2).contiguous().view(B,T,C)\n","\n","    return headOutput\n","\n","class DecoderBlock(nn.Module):\n","  def __init__(self, dFf, d_k, n_heads, vocabSize, blockSize, processor = 'cpu'):\n","    super().__init__()\n","    self.selfAttn = multiHeadAttn(dFf, d_k, n_heads, vocabSize, blockSize, processor)\n","\n","    self.FFN = nn.Sequential(\n","                nn.Linear(d_k, dFf),\n","                nn.ReLU(),\n","                nn.Linear(dFf, d_k)\n","        )\n","\n","    self.ln = LayerNorm(d_k, False).to(device = processor)\n","\n","\n","  def forward(self, qkv):\n","    x = self.selfAttn(qkv)\n","    x = x + self.ln(x)\n","    x = self.FFN(x)\n","    x = x + self.ln(x)\n","    return x\n","\n","class theTransformer(nn.Module):\n","  def __init__(self, attnLayers, dFf, d_k, parallelHeads, vocabSize, blockSize, processor = 'cpu'):\n","    super().__init__()\n","    self.d_k = d_k\n","    self.embedTok = nn.Embedding(vocabSize, d_k) #vocabSize, channelsWanted\n","    self.embedPos = nn.Embedding(blockSize, d_k) #vocabSize, channelsWanted\n","    self.decoder = DecoderBlock(dFf, d_k, parallelHeads, vocabSize, blockSize, processor) #instantiate decoder block\n","    self.layers = nn.ModuleList([self.decoder for decoders in range(attnLayers)])\n","    self.LinearFinal = nn.Linear(self.d_k, vocabSize)\n","    self.processor = processor\n","\n","  def forward(self, batchData, target, pos, training = True, softmax = True):\n","    x = self.embedTok(batchData) + self.embedPos(pos)\n","    for l in self.layers: # running through all the decoder layers we wanted\n","      x = l(x)\n","    logits = self.LinearFinal(x) # get per token logits for later backprop\n","    B,T,C = logits.shape\n","\n","    if softmax:\n","      logits = torch.softmax(logits, dim = 1) # get per token probabilities for later backprop\n","\n","      #the cross_entropy function has dimension requirement which we solve by making pred dim = (B*T, C) and target dim = (B*T) (C is classes not channels, while target has ground truth so only 1 class)\n","      pred, target = logits.view(B*T, C), F.one_hot(target.long().view(B*T), num_classes = 65).type(torch.FloatTensor)#if we want to use softmax (need to convert one-hot encoding to float so it can actually do cross entropy operations with pred which is float)\n","    else:\n","      pred, target = logits.view(B*T, C), target.long().view(B*T)\n","\n","    if training:\n","      #remember, targets are offset by one token to the future, so this loss function pushes the model towards predicting the next token using the encoded information\n","      loss = F.cross_entropy(pred, target)#.to(device = self.processor)\n","    else:\n","      # logits = logits.view(B*T, C) #\n","      logits = logits[:, [-1],:]\n","      loss = None\n","\n","    return loss, logits\n","\n","\n","def train(data, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, lEpochs, softmax, lLearningRate, processor = 'cpu'):\n","\n","  split = int(0.9*len(data)) #decided that we can se 90% on the dataset\n","  valData = data[split:]\n","  data = data[:split]\n","\n","  numericRepresentation = wordToTensor(data,tokenMapping) #changing character to index-based integer\n","\n","  finalTransformer = theTransformer(lNLayers, lDff, lD_k, lParallelHeads, lVocabSize, lBlockSize, processor)\n","\n","  finalTransformer.to(device = processor)\n","\n","  optimizer = torch.optim.Adam(finalTransformer.parameters(), lr=lLearningRate) #make optimizer for the decoder block\n","\n","  i = 0\n","  measurementsPerEpoch = 10\n","  # resolutionFactor = (1/(measurementsPerEpoch))\n","  dataLength = len(data)\n","\n","  for e in range(lEpochs):\n","    for batchData, forwardPrediction in myDataLoader(numericRepresentation, lBatchSize, lBlockSize):\n","      optimizer.zero_grad()\n","      loss, outputLogits = finalTransformer(torch.IntTensor(batchData).to(device = processor), torch.LongTensor(forwardPrediction).to(device = processor) , lPos.to(device = processor), softmax=softmax)\n","      loss.backward()\n","      optimizer.step()\n","\n","      i += 1\n","      # print(int((len(data)/len(batchData)) / measurementsPerEpoch))\n","      if  i % int((dataLength/(lBatchSize*lBlockSize)) / measurementsPerEpoch) == 0:\n","        print(e, loss)\n","\n","      if i  % int((dataLength/(lBatchSize*lBlockSize)) / (measurementsPerEpoch / 5)) == 0 :\n","        saveModel(finalTransformer)\n","        val(finalTransformer, valData, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, softmax, lLearningRate, measurementsPerEpoch, processor)\n","        i = 0\n","        finalTransformer.train()\n","\n","def val(transformerEvalModel, dataVal, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, softmax, lLearningRate, measurementsPerEpoch, processor = 'cpu'):\n","\n","  numericRepresentationEval = wordToTensor(dataVal,tokenMapping) #changing character to index-based integer\n","\n","  transformerEvalModel.to(device = processor)\n","\n","  ii = 0\n","\n","  transformerEvalModel.eval()\n","\n","  print('validation set:')\n","\n","  dataLength = len(dataVal)\n","  with torch.no_grad():\n","    for  batchData, forwardPrediction in myDataLoader(numericRepresentationEval, lBatchSize, lBlockSize):\n","      loss, outputLogits = transformerEvalModel(torch.IntTensor(batchData).to(device = processor), torch.LongTensor(forwardPrediction).to(device = processor) , lPos.to(device = processor), softmax=softmax)\n","\n","      ii += 1\n","      # print(int((dataLength/(lBatchSize*lBlockSize)) / (measurementsPerEpoch / 5)))\n","      if ii  % int((dataLength/(lBatchSize*lBlockSize)) / (measurementsPerEpoch / 5)) == 0:\n","        print('validation loss: ', loss)\n","        ii = 0\n","\n","#====================================\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Czdv_HFfRH-6","executionInfo":{"status":"ok","timestamp":1693163204262,"user_tz":240,"elapsed":935,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"63f6a758-2051-4284-a622-d284262d3bf8"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data, gTokens, gVocabSize = getRawData()\n","\n","gChannelsWanted = 64 # hopefully a good enough embdding to learn required features\n","gD_k = gChannelsWanted\n","gDff = 128 #for intermediary feedforward process\n","gParallelHeads = 8 #for batch processing\n","gNLayers = 1 #how many blocks to use to make deeper network\n","gBatchSize = 8\n","gBlockSize = 16\n","gLearningRate = 1e-3\n","gPos = torch.arange(0, gBlockSize, dtype=torch.long) #to make a kind of positional embedding\n","gEpochs = 20\n","vocab = gTokens # !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","tokenMapping = {k:v for v, k in enumerate(vocab)} #make dict where value is index of token and key is token itself\n","softmax = False\n","usedProcessor = 'cuda'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HbcoGHCnSWoq","executionInfo":{"status":"ok","timestamp":1693163205888,"user_tz":240,"elapsed":1638,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"420709e3-fc38-43e8-996c-52d34a6cadd5"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["length of raw dataset: 1,115,394\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-1SEdA1zl-cc","executionInfo":{"status":"ok","timestamp":1693163205890,"user_tz":240,"elapsed":8,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["train(data, tokenMapping, gDff, gD_k, gNLayers, gParallelHeads, gVocabSize, gBatchSize, gBlockSize, gPos, gEpochs,  softmax, gLearningRate, usedProcessor)"],"metadata":{"id":"6TyFGOUX0cVL","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1693163219206,"user_tz":240,"elapsed":9816,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"9a27d99c-710d-4fa2-dbfc-b597a01f10fc"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["0 tensor(2.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n","0 tensor(1.9135, device='cuda:0', grad_fn=<NllLossBackward0>)\n","0 tensor(2.0232, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-16a7d90b4101>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgDff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgD_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgNLayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgParallelHeads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgVocabSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgBlockSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgPos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgEpochs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgLearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musedProcessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-44-99cba0892a12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, tokenMapping, lDff, lD_k, lNLayers, lParallelHeads, lVocabSize, lBatchSize, lBlockSize, lPos, lEpochs, softmax, lLearningRate, processor)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatchData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforwardPrediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericRepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlBlockSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforwardPrediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlPos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-99cba0892a12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batchData, target, pos, training, softmax)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# running through all the decoder layers we wanted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearFinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get per token logits for later backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-99cba0892a12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qkv)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselfAttn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-99cba0892a12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qkv)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0msuccessiveTokensMask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtril\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# setting everything ahead of the mask to infinity to make sure labels aren't included in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mQkDotProduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQkDotProduct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccessiveTokensMask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;31m#gives scores per query with respect to the key it matches (softmax on final dim with shape = B, T, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mdotProdAttn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQkDotProduct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"-PWyz8jGYw34","executionInfo":{"status":"aborted","timestamp":1693019984521,"user_tz":240,"elapsed":17,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZaBUnWCQ12Az"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/myRepository/savedModels/model_20230827183324.pth'\n","finalTransformer = torch.load(path)"],"metadata":{"id":"nsjnHEOG12K5","executionInfo":{"status":"ok","timestamp":1693161274759,"user_tz":240,"elapsed":145,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def loadModel(model, pathReq):\n","  model.load_state_dict(torch.load(pathReq))\n","  model.eval()\n","  return model\n","\n","path = '/content/drive/MyDrive/myRepository/savedModels/model_20230823193630.pth'\n","finalTransformer = theTransformer(gNLayers, gDff, gD_k, gParallelHeads, gVocabSize, gBlockSize)\n","finalTransformer = loadModel(finalTransformer, path)"],"metadata":{"id":"t9xzVwzofEsT","colab":{"base_uri":"https://localhost:8080/","height":549},"executionInfo":{"status":"error","timestamp":1693155396026,"user_tz":240,"elapsed":6660,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"388b4325-044a-4922-dfde-ec87bad425d0"},"execution_count":9,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-8a11300ab406>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/myRepository/savedModels/model_20230823193630.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfinalTransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgNLayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgDff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgD_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgParallelHeads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgVocabSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgBlockSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfinalTransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-8a11300ab406>\u001b[0m in \u001b[0;36mloadModel\u001b[0;34m(model, pathReq)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathReq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for theTransformer:\n\tUnexpected key(s) in state_dict: \"layers.1.selfAttn.encodeQ.weight\", \"layers.1.selfAttn.encodeQ.bias\", \"layers.1.selfAttn.encodeK.weight\", \"layers.1.selfAttn.encodeK.bias\", \"layers.1.selfAttn.encodeV.weight\", \"layers.1.selfAttn.encodeV.bias\", \"layers.1.FFN.0.weight\", \"layers.1.FFN.0.bias\", \"layers.1.FFN.2.weight\", \"layers.1.FFN.2.bias\", \"layers.1.ln.weight\", \"layers.2.selfAttn.encodeQ.weight\", \"layers.2.selfAttn.encodeQ.bias\", \"layers.2.selfAttn.encodeK.weight\", \"layers.2.selfAttn.encodeK.bias\", \"layers.2.selfAttn.encodeV.weight\", \"layers.2.selfAttn.encodeV.bias\", \"layers.2.FFN.0.weight\", \"layers.2.FFN.0.bias\", \"layers.2.FFN.2.weight\", \"layers.2.FFN.2.bias\", \"layers.2.ln.weight\". \n\tsize mismatch for decoder.FFN.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for decoder.FFN.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder.FFN.2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for layers.0.FFN.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for layers.0.FFN.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for layers.0.FFN.2.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([64, 128])."]}]},{"cell_type":"code","source":["finalTransformer.state_dict()['embedPos.weight'].shape#.theTransformer('embedPos')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyX_Wb3894KB","executionInfo":{"status":"ok","timestamp":1693161572015,"user_tz":240,"elapsed":134,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"e8d50de6-ab63-41b4-ef3d-e29572690e12"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 64])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["modelComponents = list(torch.load(path).keys())\n","\n","for c in modelComponents:\n","  print(c, torch.load(path)[c].shape)"],"metadata":{"id":"f1z0aW_vcLvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["blockSize = torch.load(path)['embedPos.weight'].shape[0]\n"],"metadata":{"id":"-DOOuvfNH5tx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693155928999,"user_tz":240,"elapsed":403,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"8c70bcdf-b697-4d02-adac-47803b7ec3af"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 64])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["def outputWords(indices, tokenMapping):\n","  s=''\n","  for els in indices:\n","    for ss in tensorToWord(els, tokenMapping):\n","      s += ss\n","  return s\n","\n","numericRepresentation = wordToTensor(data,tokenMapping) #changing character to index-based integer\n","\n","def generateScript(blockSize, outputSizeWanted, numericRepresentation, tokenMapping=None):\n","\n","  outString = ''\n","  i = 0\n","  inferenceData = numericRepresentation[:blockSize] #get next batch\n","\n","  outString = outputWords(torch.Tensor(inferenceData).int().unsqueeze(0), tokenMapping)#just to have the initial output properly\n","\n","  while i <= (outputSizeWanted - outputSizeWanted % blockSize): #subtract whatever is remaining in the block size if it's not exactly divisible by the size wanted\n","    gPos = torch.arange(0,blockSize, dtype=torch.long) #adding pos embedding\n","\n","    loss, outputLogits = finalTransformer(torch.LongTensor(inferenceData).unsqueeze(0), torch.LongTensor(inferenceData).unsqueeze(0) , gPos, training=False, softmax=False)\n","\n","    outputLogits = outputLogits[:, -1, :] #last token in the timestep\n","\n","    i += 1\n","\n","    probs = F.softmax(outputLogits, dim=-1) # (B, C)\n","\n","    ind = torch.multinomial(probs.float(), num_samples=1) # (B, 1)\n","\n","\n","    inferenceData = torch.cat((torch.LongTensor(inferenceData), ind.long().squeeze(0)), dim = 0) #adding newest predictions into the inference data itself so it generates the string on its own\n","\n","\n","    outString += tensorToWord(ind, tokenMapping)[0]\n","\n","    if len(inferenceData) >= blockSize:\n","      inferenceData = inferenceData[-blockSize:] #making sure next batch is less than blockSize\n","\n","    if i % 100 == 0:\n","      print(outString)\n","      outString = ''\n","charsWanted=5000\n","block=gBlockSize\n","i=0\n","ss = ''\n","\n","generateScript(block, charsWanted, numericRepresentation, tokenMapping)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"pmC27Bd9XPay","executionInfo":{"status":"error","timestamp":1693156122650,"user_tz":240,"elapsed":423,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"6e83f69a-9aa7-4171-a9bb-78c19fdb68b5"},"execution_count":23,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-8cd90bcdbbf3>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mgenerateScript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcharsWanted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumericRepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-8cd90bcdbbf3>\u001b[0m in \u001b[0;36mgenerateScript\u001b[0;34m(blockSize, outputSizeWanted, numericRepresentation, tokenMapping)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgPos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblockSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#adding pos embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferenceData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferenceData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgPos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutputLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputLogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#last token in the timestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"]}]},{"cell_type":"code","source":["8"],"metadata":{"id":"0qaPanVNMHdC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(model, idx, max_new_tokens, block_size):\n","    # idx is (B, T) array of indices in the current context\n","    for _ in range(max_new_tokens):\n","        # crop idx to the last block_size tokens\n","        idx_cond = idx[:, -block_size:]\n","        # get the predictions\n","\n","        loss, logits = model(torch.LongTensor(idx_cond).unsqueeze(0), torch.LongTensor(idx_cond).unsqueeze(0) , gPos, training=False)\n","        # focus only on the last time step\n","        logits = logits[:, -1, :] # becomes (B, C)\n","        # apply softmax to get probabilities\n","        probs = torch.max(logits, dim = 1)[1]#F.softmax(logits, dim=-1) # (B, C)\n","        # print(probs.shape)\n","        # sample from the distribution\n","        idx_next = torch.multinomial(probs.unsqueeze(0).float(), num_samples=1) # (B, 1)\n","        # append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","    return idx"],"metadata":{"id":"qhZwUikHwADR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","context = torch.zeros((1, 1), dtype=torch.long, device='cpu')\n","print(tensorToWord(generate(finalTransformer, context, 2000, block)[0], tokenMapping))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"id":"jn0GT31jwAGw","executionInfo":{"status":"error","timestamp":1692817945288,"user_tz":240,"elapsed":15,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"ecff00c1-cee1-42f6-8bd7-b3405483a379"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 1])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-d6b44c04e57d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorToWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-30-7b9e6e6c064d>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(model, idx, max_new_tokens, block_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# get the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgPos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# focus only on the last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# becomes (B, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-df18ab3c2ad6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batchData, target, pos, training, softmax)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# running through all the decoder layers we wanted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearFinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get per token logits for later backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-df18ab3c2ad6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qkv)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselfAttn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-df18ab3c2ad6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, qkv)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodeQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#same process for all 3 (see paper multi-head attn figure)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"]}]},{"cell_type":"code","source":["context.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEqLFJkUy8xr","executionInfo":{"status":"ok","timestamp":1692817866101,"user_tz":240,"elapsed":386,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"3ffeef4b-8baa-48f7-fecf-e873aadb2bdd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 1])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[],"metadata":{"id":"Ui4IKBSJy80L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PqaGPIHYYgPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data, gTokens, gVocabSize = getRawData()\n","\n","gChannelsWanted = 256 # hopefully a good enough embdding to learn required features\n","gD_k = gChannelsWanted\n","gDff = 1024 #for intermediary feedforward process\n","gParallelHeads = 8 #for batch processing\n","gNLayers = 5 #how many blocks to use to make deeper network\n","gBatchSize = 5\n","gBlockSize = 10\n","gLearningRate = 1e-5\n","gPos = torch.arange(0, gBlockSize, dtype=torch.long) #to make a kind of positional embedding\n","gEpochs = 5\n","vocab = gTokens # !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","tokenMapping = {k:v for v, k in enumerate(vocab)} #make dict where value is index of token and key is token itself\n","softmax = True\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLwEUDRHYgSM","executionInfo":{"status":"ok","timestamp":1692726922128,"user_tz":240,"elapsed":644,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"86403bf5-5fd3-4732-9675-92ed842425bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["length of raw dataset: 1,115,394\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def myDataLoader(dataSet, batchSize, blockSize):\n","  batch = []\n","  toPredict = []\n","  i = 0\n","  block = 0\n","  toShuffle = np.arange(0,batchSize)\n","  np.random.shuffle(toShuffle)\n","\n","  for b in range(0, len(dataSet)//blockSize):\n","    batch.append(dataSet[block : (block + blockSize)])\n","    toPredict.append(dataSet[block + 1 : (block + 1 + blockSize)]) #adding next letter for the one to predict\n","    block += blockSize\n","    if (b+1) % batchSize == 0:\n","      # yield batch, toPredict\n","      yield np.array(batch)[toShuffle], np.array(toPredict)[toShuffle]\n","      batch = []\n","      toPredict = []\n","\n","numericRepresentation = wordToTensor(data,tokenMapping) #changing character to index-based integer\n","\n","for batchData, forwardPrediction in myDataLoader(numericRepresentation, gBatchSize, gBlockSize):\n","  print(batchData, forwardPrediction)\n","  break"],"metadata":{"id":"SoXFxC7OfEvB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692727897299,"user_tz":240,"elapsed":263,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"b23547e7-4920-4cde-c1b0-c463fceca91a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[43  1 61 43  1 54 56 53 41 43]\n"," [18 47 56 57 58  1 15 47 58 47]\n"," [58 46 43 56  6  1 46 43 39 56]\n"," [43 42  1 39 52 63  1 44 59 56]\n"," [64 43 52 10  0 14 43 44 53 56]] [[ 1 61 43  1 54 56 53 41 43 43]\n"," [47 56 57 58  1 15 47 58 47 64]\n"," [46 43 56  6  1 46 43 39 56  1]\n"," [42  1 39 52 63  1 44 59 56 58]\n"," [43 52 10  0 14 43 44 53 56 43]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","a=np.arange(0,5)\n","np.random.shuffle(a)\n","a, np.array(batchData)[np.arange(0,5)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8NEpjwEYev9","executionInfo":{"status":"ok","timestamp":1692727744517,"user_tz":240,"elapsed":518,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"11482b4f-cd9c-4c23-bbf2-1ea4b0434b19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 2, 3, 4, 1]),\n"," array([[18, 47, 56, 57, 58,  1, 15, 47, 58, 47],\n","        [64, 43, 52, 10,  0, 14, 43, 44, 53, 56],\n","        [43,  1, 61, 43,  1, 54, 56, 53, 41, 43],\n","        [43, 42,  1, 39, 52, 63,  1, 44, 59, 56],\n","        [58, 46, 43, 56,  6,  1, 46, 43, 39, 56]]))"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4e1fEjoYeyY","executionInfo":{"status":"ok","timestamp":1692727528343,"user_tz":240,"elapsed":5,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"9c569cfb-3f0d-4803-e435-095c3c3fcaec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 0, 7, 9, 1, 8, 4, 3, 6, 5])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from sklearn.model_selection import cross_validate\n","def cross_validation(model, _X, _y, _cv=5):\n","\n","      results = cross_validate(estimator=model,\n","                               X=_X,\n","                               y=_y,\n","                               cv=_cv,\n","                               scoring=_scoring,\n","                               return_train_score=True)\n","\n","\n","def gridSearch(model, X_train, y_train):\n","  param_grid = {'C': [0.1, 1, 10, 100],\n","                'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n","                'gamma':['scale', 'auto'],\n","                'kernel': ['linear']}\n","\n","  grid = GridSearchCV(model, param_grid, refit = True, verbose = 3,n_jobs=-1)\n","\n","  # fitting the model for grid search\n","  grid.fit(X_train, y_train)\n","\n","\n","\n"],"metadata":{"id":"w9bu8raknzUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Yk1fAefEnzW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class test(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # self.e = nn.Embedding(65, 128)\n","\n","    self.embedTok = nn.Embedding(65, 128) #vocabSize, channelsWanted\n","    self.embedPos = nn.Embedding(65, 128) #vocabSize, channelsWanted\n","    self.ff = nn.Linear(128, 128)\n","    self.decoder = DecoderBlock(65, 128, 1, gVocabSize, gBlockSize) #instantiate decoder block\n","    self.LinearFinal = nn.Linear(128, gVocabSize)\n","    self.layers = nn.ModuleList([self.decoder for decoders in range(3)])\n","\n","  def forward(self, x, y):\n","    l = self.embedTok(x)# +  self.embedPos(gPos)\n","    # l = self.ff(l)\n","    for ll in self.layers: # running through all the decoder layers we wanted\n","      l = ll(l)\n","    # l = self.decoder(l)\n","    l = self.LinearFinal(l)\n","    B,T,C = l.shape\n","    # l = torch.softmax(l, dim = 1)\n","    loss = F.cross_entropy(l.view(B*T,C), y.view(B*T))\n","    return loss, l\n","\n","t = test()\n","print('parameters: ', gNLayers, gDff, gD_k, gParallelHeads, gVocabSize, gBlockSize)\n","\n","finalTransformer = theTransformer(gNLayers, gDff, 128, gParallelHeads, gVocabSize, gBlockSize)\n","\n","numericRepresentation = wordToTensor(data,tokenMapping) #changing character to index-based integer\n","optimizer = torch.optim.Adam(finalTransformer.parameters(), lr=1e-3) #make optimizer for the decoder block\n","\n","# optimizer = torch.optim.Adam(t.parameters(), lr=1e-3) #make optimizer for the decoder block\n","\n","i = 0\n","for batchData, forwardPrediction in myDataLoader(numericRepresentation, gBatchSize, gBlockSize):\n","  optimizer.zero_grad()\n","  loss, l = finalTransformer(torch.IntTensor(batchData),torch.LongTensor(forwardPrediction), gPos)\n","  # loss, l = t(torch.IntTensor(batchData),torch.LongTensor(forwardPrediction))\n","  loss.backward() #dE/dy\n","  optimizer.step()\n","  i+=1\n","\n","  if i%100 == 0:\n","    print(loss)\n"],"metadata":{"id":"r43O2Hgusfw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class test(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.d_k = 128\n","    self.embedTok = nn.Embedding(65, 128) #vocabSize, channelsWanted\n","    self.embedPos = nn.Embedding(10, 128) #vocabSize, channelsWanted\n","    self.decoder = DecoderBlock(64, 128, 1, 65, 10) #instantiate decoder block\n","    self.layers = nn.ModuleList([self.decoder for decoders in range(3)])\n","    self.LinearFinal = nn.Linear(128, 65)\n","\n","  def forward(self, x, y):\n","    l = self.embedTok(x)# +  self.embedPos(gPos)\n","    # l = self.ff(l)\n","    for ll in self.layers: # running through all the decoder layers we wanted\n","      l = ll(l)\n","    # l = self.decoder(l)\n","    l = self.LinearFinal(l)\n","    B,T,C = l.shape\n","    # l = torch.softmax(l, dim = 1)\n","    loss = F.cross_entropy(l.view(B*T,C), y.view(B*T))\n","    return loss, l"],"metadata":{"id":"uSHl4Qounh33"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class test(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    # self.e = nn.Embedding(65, 128)\n","\n","    self.embedTok = nn.Embedding(65, 128) #vocabSize, channelsWanted\n","    self.embedPos = nn.Embedding(65, 128) #vocabSize, channelsWanted\n","    self.ff = nn.Linear(128, 128)\n","    self.decoder = DecoderBlock(65, 128, 1, gVocabSize, gBlockSize) #instantiate decoder block\n","    self.LinearFinal = nn.Linear(128, gVocabSize)\n","    self.layers = nn.ModuleList([self.decoder for decoders in range(3)])\n","\n","  def forward(self, x, y):\n","    l = self.embedTok(x) +  self.embedPos(gPos)\n","    # l = self.ff(l)\n","    for ll in self.layers: # running through all the decoder layers we wanted\n","      l = ll(l)\n","    # l = self.decoder(l)\n","    l = self.LinearFinal(l)\n","    B,T,C = l.shape\n","    # l = torch.softmax(l, dim = 1)\n","    loss = F.cross_entropy(l.view(B*T,C), y.view(B*T))\n","    return loss, l"],"metadata":{"id":"JXEMNjqCkda_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batchData, forwardPrediction in myDataLoader(numericRepresentation, gBatchSize, gBlockSize):\n","  optimizer.zero_grad()\n","  loss, outputLogits = finalTransformer(torch.IntTensor(batchData), torch.LongTensor(forwardPrediction) , gPos)\n","  loss.backward()\n","  optimizer.step()\n","\n","  i+=1\n","  if i % 100 == 0:\n","    print(loss)"],"metadata":{"id":"CC64fqrophj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rnZuCEA2n8FR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","torch.multinomial(a, 3)[0,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBL_yUj9o8hP","executionInfo":{"status":"ok","timestamp":1691960572737,"user_tz":240,"elapsed":341,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"5d7bf1d3-2cb6-4843-d870-cbe5cc798cbe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 1, 0])"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["a[list(torch.tensor([0,1]))]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66UGmreEo8od","executionInfo":{"status":"ok","timestamp":1691960668071,"user_tz":240,"elapsed":306,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"ea8d0c85-eb50-4cdd-e586-d2db6ed19656"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["a[list(torch.multinomial(a, 3)[0])]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"_aWB6Xk_n9iX","executionInfo":{"status":"error","timestamp":1691960654470,"user_tz":240,"elapsed":295,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"a2a930c0-35a4-44af-daf0-2e66fd19ee74"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-e9e07d1eb9bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"]}]},{"cell_type":"code","source":["tokEmbeddedTarget.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4qqTEz4QC9F","executionInfo":{"status":"ok","timestamp":1691935749688,"user_tz":240,"elapsed":135,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"b0b8dee4-de68-43ac-b7d7-751227d2a6ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 3, 32])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["torch.max(outputLogits, dim = 1)[1]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k58grnXFwkFb","executionInfo":{"status":"ok","timestamp":1691886447555,"user_tz":240,"elapsed":136,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"4957bdeb-a32c-4f61-b9d0-eccebeaa6f70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 1, 1, 0, 2, 0, 1, 2, 2, 2, 0, 1, 1, 1, 0,\n","         2, 1, 0, 0, 0, 1, 0, 0],\n","        [2, 2, 1, 2, 2, 0, 2, 2, 1, 1, 1, 1, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 0,\n","         1, 2, 2, 0, 1, 1, 0, 0],\n","        [2, 1, 1, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 0, 1,\n","         2, 1, 0, 0, 0, 1, 0, 0],\n","        [2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 0, 0,\n","         2, 2, 0, 0, 0, 2, 0, 0],\n","        [2, 0, 0, 2, 1, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 1, 0, 1, 2, 2, 0,\n","         2, 2, 0, 0, 1, 2, 0, 0]])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["tokEmbedded.transpose(1,2).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zvTm04NWVRo","executionInfo":{"status":"ok","timestamp":1691807833388,"user_tz":240,"elapsed":133,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"a5056572-81bf-4f66-824f-05e7a6faebed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 32, 3])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["torch.tril(torch.ones(4,4)).view(1,1,4,4)[:,:,:3,:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffoVNUu16goh","executionInfo":{"status":"ok","timestamp":1691448930606,"user_tz":240,"elapsed":122,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"d7c9798b-38f3-4a3e-966e-8d26e15f4e1a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[1., 0., 0.],\n","          [1., 1., 0.],\n","          [1., 1., 1.]]]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["vocab = gTokens # !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","tokenMapping = {k:v for v, k in enumerate(vocab)} #make dict where value is index of token and key is token itself\n","encoded(batchData,tokenMapping)"],"metadata":{"id":"EPAVrNNK6gq0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691537656557,"user_tz":240,"elapsed":133,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"9acdef23-3d09-4ff4-d339-176aed14d6cc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# def myDataLoaderTest(dataSet, batchSize):\n","#   batch=torch.zeros([0, dataSet.shape[1]])\n","#   for i in range(0,len(dataSet)-1):\n","#     print(dataSet[i].shape)\n","#     batch = torch.cat((batch, dataSet[i].unsqueeze(0)))\n","#     if (i+1) % batchSize == 0:\n","#       yield batch\n","#       batch=torch.zeros([0, dataSet.shape[1]])\n","\n","# batchSize = 2\n","# for batchQ in myDataLoaderTest(Q, batchSize):\n","#   print(batchQ)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O20eZCVG1Q0z","executionInfo":{"status":"ok","timestamp":1691417090663,"user_tz":240,"elapsed":314,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"cb45cdaa-5b58-4d49-f331-b8c9b6e8ec77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32])\n","torch.Size([32])\n","tensor([[ 0.5041, -0.9131, -0.1429, -0.4240,  0.4396, -1.4560, -0.8116, -1.7094,\n","         -0.3268,  0.6555,  0.7870, -0.0894,  0.3712,  0.8852,  1.2754,  0.8494,\n","          0.2138,  2.5678,  0.4228, -0.7758,  0.8885,  0.7045, -0.3161,  0.0702,\n","          0.6461,  0.4944,  0.2393,  0.3691,  1.5256,  0.0490,  0.3267, -0.0966],\n","        [ 0.5341, -1.1854,  1.1431,  0.3176, -2.1182, -0.2435,  0.0195, -0.6521,\n","         -0.2863, -0.1673,  0.7450, -0.4235,  0.4813, -0.5032, -0.7629,  0.3685,\n","         -0.1149,  0.8566, -0.2689,  2.1706, -0.7868, -0.4887, -0.1091, -0.4100,\n","         -0.4694,  1.0157, -0.9289, -1.2968,  1.2652,  0.7866, -0.1124,  2.0612]],\n","       grad_fn=<CatBackward0>)\n","torch.Size([32])\n","torch.Size([32])\n","tensor([[ 1.4053e+00, -2.0466e-03, -1.6517e+00, -1.8867e+00,  9.9712e-01,\n","         -1.4177e+00, -1.2179e-01, -1.1781e+00,  1.4940e+00,  1.8120e-01,\n","         -5.4727e-01,  1.4965e-01,  3.7345e-01,  1.1907e+00, -4.3360e-01,\n","          1.4760e+00, -2.2140e-01, -2.3985e+00, -1.1066e+00,  7.9194e-01,\n","          2.9550e-01, -1.3632e+00,  1.9760e+00,  5.7931e-01,  1.3495e-01,\n","          9.7592e-01, -7.0192e-01,  9.9457e-01, -6.5402e-01, -1.1201e+00,\n","         -4.7577e-01, -1.2546e+00],\n","        [ 1.4053e+00, -2.0466e-03, -1.6517e+00, -1.8867e+00,  9.9712e-01,\n","         -1.4177e+00, -1.2179e-01, -1.1781e+00,  1.4940e+00,  1.8120e-01,\n","         -5.4727e-01,  1.4965e-01,  3.7345e-01,  1.1907e+00, -4.3360e-01,\n","          1.4760e+00, -2.2140e-01, -2.3985e+00, -1.1066e+00,  7.9194e-01,\n","          2.9550e-01, -1.3632e+00,  1.9760e+00,  5.7931e-01,  1.3495e-01,\n","          9.7592e-01, -7.0192e-01,  9.9457e-01, -6.5402e-01, -1.1201e+00,\n","         -4.7577e-01, -1.2546e+00]], grad_fn=<CatBackward0>)\n"]}]},{"cell_type":"code","source":["Q.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxbRy4GUKa86","executionInfo":{"status":"ok","timestamp":1691417159649,"user_tz":240,"elapsed":4,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"18729499-5906-4c1c-8b5c-364e6f726014"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["Q.unsqueeze(0).shape, K.permute(1,0).shape"],"metadata":{"id":"LeHDLmG7xwPk","executionInfo":{"status":"ok","timestamp":1691353089738,"user_tz":240,"elapsed":133,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30a0c26d-3037-491c-8ce2-dc898893560a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 5, 32]), torch.Size([65, 32]))"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# list(d.keys())\n","encoded = lambda sInput: [d[letter] for letter in sInput]\n","decoded = lambda sIndexes: [list(d.keys())[i] for i in sIndexes]\n","encoded('ab'),decoded([0,2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ob7z0mEWxwTP","executionInfo":{"status":"ok","timestamp":1691341790782,"user_tz":240,"elapsed":6,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"2949af09-52f4-483a-dde9-bcae194ccc97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0, 1], ['a', 'c'])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["def gen(dataSet, batchSize):\n","  batch=[]\n","  for i in range(1,len(dataSet)):\n","    batch.append(dataSet[i])\n","    if i % batchSize == 0:\n","      yield batch\n","      batch=[]\n","\n","dataSet=encoded('hello, world')\n","batchSize = 2\n","for i in gen(dataSet, batchSize):\n","  print(i)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvMJL8-J1VLl","executionInfo":{"status":"ok","timestamp":1691358460579,"user_tz":240,"elapsed":4,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"ffc2cf12-1770-4b0a-8e98-f9f8f0885014"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[43, 50]\n","[50, 53]\n","[6, 1]\n","[61, 53]\n","[56, 50]\n"]}]},{"cell_type":"code","source":["a=torch.Tensor([\n","                [[2,1],[2,1]],\n","               [[5,5],[6,6]]\n","                ])\n","\n","b=torch.Tensor([\n","              [[3,1],[4,1]],\n","               [[4,1],[4,2]],\n","              [[4,1],[4,2]]\n","            ]\n","              )\n","\n","torch.matmul(a,b.T) #batchSize,"],"metadata":{"id":"CvlJmPgI1VOL","executionInfo":{"status":"ok","timestamp":1691335969790,"user_tz":240,"elapsed":306,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"219d0117-87b6-4124-9d7d-43c4e89bde2b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[10., 12., 12.],\n","         [10., 12., 12.]],\n","\n","        [[10., 15., 15.],\n","         [12., 18., 18.]]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"-eUWHFWx1kl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b.shape, b.T.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UP2aajqZey_h","executionInfo":{"status":"ok","timestamp":1691336016795,"user_tz":240,"elapsed":311,"user":{"displayName":"Sajeel Khalid","userId":"17554249077233151040"}},"outputId":"db8b9733-d4ea-4234-820d-1e7b52745d3e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([3, 2, 2]), torch.Size([2, 2, 3]))"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[],"metadata":{"id":"0ycVCtjWezn-"},"execution_count":null,"outputs":[]}]}